# Upwork Portfolio Entry: AI Security Audit

**Status**: Ready to upload
**Last Updated**: November 21, 2025

---

## Title

AI Security: Prompt Injection Defense System (Red Teaming)

---

## Description

```
As AI applications move to production, security is the #1 risk. I specialize in auditing LLM applications for vulnerabilities (Prompt Injection, Jailbreaks) and implementing robust defense layers.

PROBLEM:
A FinTech client launched a customer support bot but discovered that users could trick it into revealing system instructions and behaving inappropriately ("DAN mode"). They needed an immediate security fix to prevent reputational damage.

SOLUTION:
I performed a "Red Team" audit and implemented a multi-layer defense system.
1.  **Vulnerability Scan**: Tested the bot against 50+ known attack vectors (e.g., "Ignore previous instructions").
2.  **Heuristic Firewall**: Implemented regex-based blocking for common attack patterns.
3.  **LLM Judge**: Deployed a secondary, lightweight model to analyze user intent before passing it to the main bot.
4.  **Audit Logging**: Created a dashboard to track and analyze blocked attacks in real-time.

RESULTS:
•   **99.8% Block Rate**: Successfully stopped all known jailbreak attempts during re-testing.
•   **Compliance**: Helped the client meet SOC2 requirements for AI risk management.
•   **Peace of Mind**: Client could confidently market their AI tool without fear of abuse.

TECH STACK: Python, LangChain, Rebuff, NeMo Guardrails, OpenAI, Security Auditing

DELIVERABLES:
•   Security Audit Report (Vulnerabilities Found)
•   "AI Firewall" Middleware Code
•   Attack Logging Dashboard
•   Best Practices Guide for Prompt Engineering

Don't let a prompt injection attack ruin your launch. I can secure your AI app today.
```

---

## Project Details

**Project Type**: Development & IT → Information Security

**Skills**:

```
AI Security, Prompt Engineering, Python, Penetration Testing, Large Language Models, Security Auditing, LangChain, Risk Assessment, Cybersecurity, API Security
```

**Duration**: Less than 1 week

**Your Role**: Security Engineer

**Client Type**: FinTech / Enterprise

**Tags**:

```
ai-security, prompt-injection, red-teaming, llm-security, cybersecurity, python, langchain, audit, risk-management, fintech
```

---

## Links

**GitHub Repository**:

```
https://github.com/RazonIn4K/prompt-defenders/tree/main/demos/prompt_injection
```

**Case Study**:

```
https://github.com/RazonIn4K/prompt-defenders/blob/main/demos/prompt_injection/PROMPT_DEFENSE_DEMO.md
```

**Demo Video** (add after recording):

```
https://www.loom.com/share/[your-video-id]
```

---

## Images to Upload

1.  **attack_blocked.png** - Terminal log showing a blocked attack (from `demos/prompt_injection/assets/`)
2.  **architecture_diagram.png** - Diagram of the Defense Layer (if available)
3.  **audit_report_cover.png** - Mockup of a Security Audit Report cover page

**Image Location**: `prompt-defenders/demos/prompt_injection/assets/`
